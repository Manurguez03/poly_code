{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f00245",
   "metadata": {},
   "source": [
    "# Defining Upsets in ATP Tennis Matches Using Betting Odds\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook performs comprehensive data cleaning and feature engineering on ATP tennis betting odds data to define and classify match upsets. The analysis spans 8 years (2016-2019, 2021-2024) and processes over 20,000 tennis matches.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. **Data Cleaning**: Remove incomplete matches (retirements and walkovers) from the betting odds datasets\n",
    "2. **Probability Calculation**: Convert betting odds into fair win probabilities for each player\n",
    "3. **Upset Definition**: Define upsets using a probability-based threshold\n",
    "4. **Binary Classification**: Create a binary feature to classify matches as upsets or non-upsets\n",
    "5. **Feature Selection**: Retain only the most relevant features for analysis\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "- **Total Matches Analyzed**: ~20,300 completed matches across 8 years\n",
    "- **Matches Removed**: 707 incomplete matches (Retired/Walkover)\n",
    "- **Upset Rate**: Approximately 6-8% of matches are classified as upsets\n",
    "- **Upset Threshold**: Matches where the winner had <30% probability of winning\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "- **Source**: ATP Betting Odds (Excel files from Atp_Betting_Odds_Folder)\n",
    "- **Years Covered**: 2016, 2017, 2018, 2019, 2021, 2022, 2023, 2024\n",
    "- **Final Features**: 17 key features per match\n",
    "- **Output**: `cleaned_betting_odds_dfs` dictionary containing cleaned dataframes for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2944aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451fbf8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Data Loading\n",
    "\n",
    "We begin by importing necessary libraries and loading all betting odds data from Excel files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1021cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Downloads\\Downloads\\ANACONDA\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85: UserWarning: Unknown extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2016: 2626 matches\n",
      "Loaded 2017: 2633 matches\n",
      "Loaded 2018: 2637 matches\n",
      "Loaded 2019: 2610 matches\n",
      "Loaded 2021: 2489 matches\n",
      "Loaded 2022: 2632 matches\n",
      "Loaded 2023: 2703 matches\n",
      "Loaded 2024: 2703 matches\n",
      "\n",
      "Total years loaded: 8\n"
     ]
    }
   ],
   "source": [
    "# Load all betting odds files\n",
    "betting_odds_folder = r'c:\\poly_code\\Atp_Betting_Odds_Folder'\n",
    "betting_odds_files = glob.glob(os.path.join(betting_odds_folder, '*.xlsx'))\n",
    "\n",
    "# Create a dictionary to store dataframes\n",
    "betting_odds_dfs = {}\n",
    "\n",
    "for file in betting_odds_files:\n",
    "    year = os.path.basename(file).split('.')[0]\n",
    "    betting_odds_dfs[year] = pd.read_excel(file)\n",
    "    print(f\"Loaded {year}: {len(betting_odds_dfs[year])} matches\")\n",
    "\n",
    "print(f\"\\nTotal years loaded: {len(betting_odds_dfs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ecbf1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in 2016 dataset:\n",
      "['ATP', 'Location', 'Tournament', 'Date', 'Series', 'Court', 'Surface', 'Round', 'Best of', 'Winner', 'Loser', 'WRank', 'LRank', 'WPts', 'LPts', 'W1', 'L1', 'W2', 'L2', 'W3', 'L3', 'W4', 'L4', 'W5', 'L5', 'Wsets', 'Lsets', 'Comment', 'B365W', 'B365L', 'EXW', 'EXL', 'LBW', 'LBL', 'PSW', 'PSL', 'MaxW', 'MaxL', 'AvgW', 'AvgL']\n",
      "\n",
      "First few rows:\n",
      "   ATP  Location              Tournament       Date  Series    Court Surface  \\\n",
      "0    1  Brisbane  Brisbane International 2016-01-04  ATP250  Outdoor    Hard   \n",
      "1    1  Brisbane  Brisbane International 2016-01-04  ATP250  Outdoor    Hard   \n",
      "2    1  Brisbane  Brisbane International 2016-01-04  ATP250  Outdoor    Hard   \n",
      "3    1  Brisbane  Brisbane International 2016-01-04  ATP250  Outdoor    Hard   \n",
      "4    1  Brisbane  Brisbane International 2016-01-05  ATP250  Outdoor    Hard   \n",
      "\n",
      "       Round  Best of       Winner  ...   EXW   EXL   LBW   LBL   PSW   PSL  \\\n",
      "0  1st Round        3  Dimitrov G.  ...  1.68  2.10  1.62  2.25  1.68  2.31   \n",
      "1  1st Round        3     Kudla D.  ...  1.58  2.35  1.53  2.50  1.63  2.40   \n",
      "2  1st Round        3     Kamke T.  ...  1.82  1.90  1.80  2.00  1.90  1.99   \n",
      "3  1st Round        3     Chung H.  ...  1.82  1.90  1.73  2.10  1.93  1.96   \n",
      "4  1st Round        3    Goffin D.  ...  1.30  3.40  1.29  3.75  1.31  3.74   \n",
      "\n",
      "   MaxW  MaxL  AvgW  AvgL  \n",
      "0  1.76  2.35  1.66  2.20  \n",
      "1  1.63  2.50  1.57  2.37  \n",
      "2  1.90  2.10  1.77  2.00  \n",
      "3  1.93  2.10  1.82  1.95  \n",
      "4  1.31  3.80  1.29  3.56  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of one dataset to see the 'Comment' column\n",
    "year_sample = list(betting_odds_dfs.keys())[0]\n",
    "print(f\"Columns in {year_sample} dataset:\")\n",
    "print(betting_odds_dfs[year_sample].columns.tolist())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(betting_odds_dfs[year_sample].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa692255",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Exploration\n",
    "\n",
    "Before cleaning, we explore the dataset structure to understand the available features and identify data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc143cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Comment' column across all years:\n",
      "\n",
      "2016: ['Completed' 'Retired' 'Walkover']\n",
      "2017: ['Completed' 'Retired' 'Walkover']\n",
      "2018: ['Completed' 'Retired' 'Walkover']\n",
      "2019: ['Completed' 'Walkover' 'Retired' 'Awarded' 'Sched']\n",
      "2021: ['Completed' 'Retired' 'Walkover' 'Awarded' 'Rrtired']\n",
      "2022: ['Completed' 'Retired' 'Walkover']\n",
      "2023: ['Completed' 'Retired' 'Walkover' 'Awarded']\n",
      "2024: ['Completed' 'Retired' 'Walkover' 'Awarded']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in Comment column across all datasets\n",
    "print(\"Unique values in 'Comment' column across all years:\\n\")\n",
    "for year, df in betting_odds_dfs.items():\n",
    "    if 'Comment' in df.columns:\n",
    "        unique_comments = df['Comment'].unique()\n",
    "        print(f\"{year}: {unique_comments}\")\n",
    "    else:\n",
    "        print(f\"{year}: No 'Comment' column found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570b76b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016: Removed 99 matches (Retired/Walkover). Remaining: 2527\n",
      "2017: Removed 103 matches (Retired/Walkover). Remaining: 2530\n",
      "2018: Removed 82 matches (Retired/Walkover). Remaining: 2555\n",
      "2019: Removed 78 matches (Retired/Walkover). Remaining: 2532\n",
      "2021: Removed 79 matches (Retired/Walkover). Remaining: 2410\n",
      "2022: Removed 85 matches (Retired/Walkover). Remaining: 2547\n",
      "2023: Removed 88 matches (Retired/Walkover). Remaining: 2615\n",
      "2024: Removed 93 matches (Retired/Walkover). Remaining: 2610\n",
      "\n",
      "Cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "# Clean the datasets by removing matches with 'Retired' or 'Walkover' in Comment column\n",
    "cleaned_betting_odds_dfs = {}\n",
    "\n",
    "for year, df in betting_odds_dfs.items():\n",
    "    if 'Comment' in df.columns:\n",
    "        # Remove rows where Comment is 'Retired' or 'Walkover'\n",
    "        original_count = len(df)\n",
    "        cleaned_df = df[~df['Comment'].isin(['Retired', 'Walkover'])].copy()\n",
    "        removed_count = original_count - len(cleaned_df)\n",
    "        cleaned_betting_odds_dfs[year] = cleaned_df\n",
    "        print(f\"{year}: Removed {removed_count} matches (Retired/Walkover). Remaining: {len(cleaned_df)}\")\n",
    "    else:\n",
    "        cleaned_betting_odds_dfs[year] = df.copy()\n",
    "        print(f\"{year}: No 'Comment' column - kept all {len(df)} matches\")\n",
    "\n",
    "print(f\"\\nCleaning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd48461",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Data Cleaning\n",
    "\n",
    "### Removing Incomplete Matches\n",
    "\n",
    "The 'Comment' column indicates match completion status. We remove matches marked as:\n",
    "- **Retired**: Player retired mid-match due to injury or other reasons\n",
    "- **Walkover**: Match awarded without play\n",
    "\n",
    "**Rationale**: These matches don't reflect true competitive outcomes and could skew upset analysis since betting odds don't account for mid-match events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e52254d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Feature Engineering: Probability of Winning\n",
    "\n",
    "### Converting Odds to Probabilities\n",
    "\n",
    "Betting odds represent the bookmaker's assessment of each player's winning chances. We convert these to probabilities using:\n",
    "\n",
    "**Formula**: $P = \\frac{1}{\\text{Odds}}$\n",
    "\n",
    "### Normalization for Fair Probabilities\n",
    "\n",
    "Bookmaker odds include a profit margin (overround), causing implied probabilities to sum to >1. We normalize to obtain fair probabilities:\n",
    "\n",
    "**Normalized Probability**: $P_{\\text{fair}} = \\frac{P_{\\text{implied}}}{P_{\\text{winner}} + P_{\\text{loser}}}$\n",
    "\n",
    "This ensures probabilities sum to exactly 1.0, representing a true probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c09da2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016: Added probability features. Sample probabilities (first match):\n",
      "  Winner prob: 0.5699, Loser prob: 0.4301, Sum: 1.0000\n",
      "2017: Added probability features. Sample probabilities (first match):\n",
      "  Winner prob: 0.7307, Loser prob: 0.2693, Sum: 1.0000\n",
      "2018: Added probability features. Sample probabilities (first match):\n",
      "  Winner prob: 0.4364, Loser prob: 0.5636, Sum: 1.0000\n",
      "2019: Added probability features. Sample probabilities (first match):\n",
      "  Winner prob: 0.7020, Loser prob: 0.2980, Sum: 1.0000\n",
      "2021: Added probability features. Sample probabilities (first match):\n",
      "  Winner prob: 0.6080, Loser prob: 0.3920, Sum: 1.0000\n",
      "2022: Added probability features. Sample probabilities (first match):\n",
      "  Winner prob: 0.5751, Loser prob: 0.4249, Sum: 1.0000\n",
      "2023: Added probability features. Sample probabilities (first match):\n",
      "  Winner prob: 0.5000, Loser prob: 0.5000, Sum: 1.0000\n",
      "2024: Added probability features. Sample probabilities (first match):\n",
      "  Winner prob: 0.5636, Loser prob: 0.4364, Sum: 1.0000\n",
      "\n",
      "Probability features added to all datasets!\n"
     ]
    }
   ],
   "source": [
    "# Calculate implied probabilities and normalize them\n",
    "for year, df in cleaned_betting_odds_dfs.items():\n",
    "    # Calculate implied probabilities using P = 1 / Odds\n",
    "    df['implied_prob_winner'] = 1 / df['AvgW']\n",
    "    df['implied_prob_loser'] = 1 / df['AvgL']\n",
    "    \n",
    "    # Calculate the sum of implied probabilities (overround)\n",
    "    df['prob_sum'] = df['implied_prob_winner'] + df['implied_prob_loser']\n",
    "    \n",
    "    # Normalize to get fair probabilities that sum to 1\n",
    "    df['prob_winner'] = df['implied_prob_winner'] / df['prob_sum']\n",
    "    df['prob_loser'] = df['implied_prob_loser'] / df['prob_sum']\n",
    "    \n",
    "    # Drop intermediate columns (implied probabilities and sum)\n",
    "    df.drop(['implied_prob_winner', 'implied_prob_loser', 'prob_sum'], axis=1, inplace=True)\n",
    "    \n",
    "    print(f\"{year}: Added probability features. Sample probabilities (first match):\")\n",
    "    print(f\"  Winner prob: {df['prob_winner'].iloc[0]:.4f}, Loser prob: {df['prob_loser'].iloc[0]:.4f}, Sum: {df['prob_winner'].iloc[0] + df['prob_loser'].iloc[0]:.4f}\")\n",
    "\n",
    "print(f\"\\nProbability features added to all datasets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bdb6d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for 2016:\n",
      "Total columns: 42\n",
      "\n",
      "New probability columns added:\n",
      "  - prob_winner\n",
      "  - prob_loser\n",
      "\n",
      "Sample data (first 3 matches):\n",
      "        Winner        Loser  AvgW  AvgL  prob_winner  prob_loser\n",
      "0  Dimitrov G.     Simon G.  1.66  2.20     0.569948    0.430052\n",
      "1     Kudla D.   Smith J.P.  1.57  2.37     0.601523    0.398477\n",
      "2     Kamke T.  Mitchell B.  1.77  2.00     0.530504    0.469496\n"
     ]
    }
   ],
   "source": [
    "# Verify the new features in one of the datasets\n",
    "year_sample = list(cleaned_betting_odds_dfs.keys())[0]\n",
    "sample_df = cleaned_betting_odds_dfs[year_sample]\n",
    "\n",
    "print(f\"Dataset for {year_sample}:\")\n",
    "print(f\"Total columns: {len(sample_df.columns)}\")\n",
    "print(f\"\\nNew probability columns added:\")\n",
    "print(f\"  - prob_winner\")\n",
    "print(f\"  - prob_loser\")\n",
    "print(f\"\\nSample data (first 3 matches):\")\n",
    "print(sample_df[['Winner', 'Loser', 'AvgW', 'AvgL', 'prob_winner', 'prob_loser']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb4f43",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Defining Upsets\n",
    "\n",
    "### Upset Criteria\n",
    "\n",
    "An **upset** is defined as a match where the winner was considered the underdog based on betting odds:\n",
    "\n",
    "**Definition**: A match is classified as an upset if:\n",
    "$$P_{\\text{winner}} < 0.30$$\n",
    "\n",
    "This threshold means the winner had less than a 30% probability of winning according to the betting markets.\n",
    "\n",
    "### Binary Classification\n",
    "\n",
    "- **upset_binary = 1**: Upset (winner was a strong underdog)\n",
    "- **upset_binary = 0**: Expected result (favorite won or competitive match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7321a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016: 205 upsets out of 2527 matches (8.11%)\n",
      "2017: 206 upsets out of 2530 matches (8.14%)\n",
      "2018: 179 upsets out of 2555 matches (7.01%)\n",
      "2019: 171 upsets out of 2532 matches (6.75%)\n",
      "2021: 173 upsets out of 2410 matches (7.18%)\n",
      "2022: 177 upsets out of 2547 matches (6.95%)\n",
      "2023: 180 upsets out of 2615 matches (6.88%)\n",
      "2024: 153 upsets out of 2610 matches (5.86%)\n",
      "\n",
      "Upset binary classification feature added to all datasets!\n"
     ]
    }
   ],
   "source": [
    "# Define upset threshold\n",
    "UPSET_THRESHOLD = 0.30\n",
    "\n",
    "# Create binary upset classification feature\n",
    "for year, df in cleaned_betting_odds_dfs.items():\n",
    "    # Upset = 1 if prob_winner < 0.30, otherwise 0\n",
    "    df['upset_binary'] = (df['prob_winner'] < UPSET_THRESHOLD).astype(int)\n",
    "    \n",
    "    # Count upsets\n",
    "    upset_count = df['upset_binary'].sum()\n",
    "    total_matches = len(df)\n",
    "    upset_percentage = (upset_count / total_matches) * 100\n",
    "    \n",
    "    print(f\"{year}: {upset_count} upsets out of {total_matches} matches ({upset_percentage:.2f}%)\")\n",
    "\n",
    "print(f\"\\nUpset binary classification feature added to all datasets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa91acd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples from 2016 dataset:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "NON-UPSETS (upset_binary = 0):\n",
      "--------------------------------------------------------------------------------\n",
      "     Winner       Loser  prob_winner  prob_loser  upset_binary\n",
      "Dimitrov G.    Simon G.     0.569948    0.430052             0\n",
      "   Kudla D.  Smith J.P.     0.601523    0.398477             0\n",
      "   Kamke T. Mitchell B.     0.530504    0.469496             0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "UPSETS (upset_binary = 1):\n",
      "--------------------------------------------------------------------------------\n",
      "    Winner        Loser  prob_winner  prob_loser  upset_binary\n",
      "Pouille L.    Goffin D.     0.189853    0.810147             1\n",
      "  Tomic B. Nishikori K.     0.284483    0.715517             1\n",
      " Raonic M.   Federer R.     0.244660    0.755340             1\n"
     ]
    }
   ],
   "source": [
    "# Display examples of upsets and non-upsets\n",
    "year_sample = list(cleaned_betting_odds_dfs.keys())[0]\n",
    "sample_df = cleaned_betting_odds_dfs[year_sample]\n",
    "\n",
    "print(f\"Examples from {year_sample} dataset:\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nNON-UPSETS (upset_binary = 0):\")\n",
    "print(\"-\" * 80)\n",
    "non_upsets = sample_df[sample_df['upset_binary'] == 0][['Winner', 'Loser', 'prob_winner', 'prob_loser', 'upset_binary']].head(3)\n",
    "print(non_upsets.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nUPSETS (upset_binary = 1):\")\n",
    "print(\"-\" * 80)\n",
    "upsets = sample_df[sample_df['upset_binary'] == 1][['Winner', 'Loser', 'prob_winner', 'prob_loser', 'upset_binary']].head(3)\n",
    "print(upsets.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497d6de",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Feature Selection\n",
    "\n",
    "### Dimensionality Reduction\n",
    "\n",
    "To focus on the most relevant information for upset analysis, we reduced the dataset from 39-43 features to 17 essential features.\n",
    "\n",
    "### Selected Features\n",
    "\n",
    "**Match Context** (8 features):\n",
    "- Location, Tournament, Date, Series, Court, Surface, Round, Best of\n",
    "\n",
    "**Players** (2 features):\n",
    "- Winner, Loser\n",
    "\n",
    "**Rankings** (2 features):\n",
    "- WRank (Winner's ATP ranking)\n",
    "- LRank (Loser's ATP ranking)\n",
    "\n",
    "**Betting Odds** (2 features):\n",
    "- AvgW (Average odds for winner)\n",
    "- AvgL (Average odds for loser)\n",
    "\n",
    "**Engineered Features** (3 features):\n",
    "- prob_winner (Fair probability of winner winning)\n",
    "- prob_loser (Fair probability of loser winning)\n",
    "- upset_binary (Binary upset classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd1aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016: Reduced from 43 to 17 features\n",
      "2017: Reduced from 43 to 17 features\n",
      "2018: Reduced from 43 to 17 features\n",
      "2019: Reduced from 39 to 17 features\n",
      "2021: Reduced from 39 to 17 features\n",
      "2022: Reduced from 39 to 17 features\n",
      "2023: Reduced from 39 to 17 features\n",
      "2024: Reduced from 39 to 17 features\n",
      "\n",
      "Feature selection complete!\n"
     ]
    }
   ],
   "source": [
    "# Define the features to keep\n",
    "features_to_keep = [\n",
    "    'Location', 'Tournament', 'Date', 'Series', 'Court', 'Surface', 'Round', \n",
    "    'Best of', 'Winner', 'Loser', 'WRank', 'LRank', 'AvgW', 'AvgL',\n",
    "    'prob_winner', 'prob_loser', 'upset_binary'\n",
    "]\n",
    "\n",
    "# Keep only the selected features in all datasets\n",
    "for year, df in cleaned_betting_odds_dfs.items():\n",
    "    # Get columns that exist in the dataframe\n",
    "    available_columns = [col for col in features_to_keep if col in df.columns]\n",
    "    \n",
    "    # Keep only selected columns\n",
    "    cleaned_betting_odds_dfs[year] = df[available_columns].copy()\n",
    "    \n",
    "    print(f\"{year}: Reduced from {len(df.columns)} to {len(available_columns)} features\")\n",
    "\n",
    "print(f\"\\nFeature selection complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93970207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining features in 2016 dataset:\n",
      "Total: 17 features\n",
      "\n",
      "Column names:\n",
      "  1. Location\n",
      "  2. Tournament\n",
      "  3. Date\n",
      "  4. Series\n",
      "  5. Court\n",
      "  6. Surface\n",
      "  7. Round\n",
      "  8. Best of\n",
      "  9. Winner\n",
      "  10. Loser\n",
      "  11. WRank\n",
      "  12. LRank\n",
      "  13. AvgW\n",
      "  14. AvgL\n",
      "  15. prob_winner\n",
      "  16. prob_loser\n",
      "  17. upset_binary\n",
      "\n",
      "Dataset shape: (2527, 17)\n",
      "\n",
      "First 3 rows:\n",
      "   Location              Tournament       Date  Series    Court Surface  \\\n",
      "0  Brisbane  Brisbane International 2016-01-04  ATP250  Outdoor    Hard   \n",
      "1  Brisbane  Brisbane International 2016-01-04  ATP250  Outdoor    Hard   \n",
      "2  Brisbane  Brisbane International 2016-01-04  ATP250  Outdoor    Hard   \n",
      "\n",
      "       Round  Best of       Winner        Loser  WRank  LRank  AvgW  AvgL  \\\n",
      "0  1st Round        3  Dimitrov G.     Simon G.   28.0   15.0  1.66  2.20   \n",
      "1  1st Round        3     Kudla D.   Smith J.P.   69.0  129.0  1.57  2.37   \n",
      "2  1st Round        3     Kamke T.  Mitchell B.  277.0  231.0  1.77  2.00   \n",
      "\n",
      "   prob_winner  prob_loser  upset_binary  \n",
      "0     0.569948    0.430052             0  \n",
      "1     0.601523    0.398477             0  \n",
      "2     0.530504    0.469496             0  \n"
     ]
    }
   ],
   "source": [
    "# Verify the remaining features\n",
    "year_sample = list(cleaned_betting_odds_dfs.keys())[0]\n",
    "sample_df = cleaned_betting_odds_dfs[year_sample]\n",
    "\n",
    "print(f\"Remaining features in {year_sample} dataset:\")\n",
    "print(f\"Total: {len(sample_df.columns)} features\\n\")\n",
    "print(\"Column names:\")\n",
    "for i, col in enumerate(sample_df.columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "print(f\"\\nDataset shape: {sample_df.shape}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "print(sample_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44399b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Summary and Results\n",
    "\n",
    "### Data Processing Pipeline\n",
    "\n",
    "1. ✅ **Loaded** 8 years of ATP betting odds data (~21,000 matches)\n",
    "2. ✅ **Cleaned** by removing 707 incomplete matches (Retired/Walkover)\n",
    "3. ✅ **Calculated** fair win probabilities using normalized betting odds\n",
    "4. ✅ **Defined** upsets as matches where winner had <30% win probability\n",
    "5. ✅ **Created** binary classification feature (upset_binary)\n",
    "6. ✅ **Reduced** features from 39-43 to 17 most relevant attributes\n",
    "\n",
    "### Key Statistics\n",
    "\n",
    "| Year | Total Matches | Upsets | Upset Rate |\n",
    "|------|--------------|--------|------------|\n",
    "| 2016 | 2,527 | 205 | 8.11% |\n",
    "| 2017 | 2,530 | 206 | 8.14% |\n",
    "| 2018 | 2,555 | 179 | 7.01% |\n",
    "| 2019 | 2,532 | 171 | 6.75% |\n",
    "| 2021 | 2,410 | 173 | 7.18% |\n",
    "| 2022 | 2,547 | 177 | 6.95% |\n",
    "| 2023 | 2,615 | 180 | 6.88% |\n",
    "| 2024 | 2,610 | 153 | 5.86% |\n",
    "| **Total** | **20,326** | **1,444** | **7.10%** |\n",
    "\n",
    "### Output\n",
    "\n",
    "The cleaned and processed data is stored in the `cleaned_betting_odds_dfs` dictionary, with each year as a key containing a pandas DataFrame with 17 features ready for further analysis, modeling, or visualization.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "This preprocessed dataset can be used for:\n",
    "- Upset prediction modeling\n",
    "- Pattern analysis in tennis upsets\n",
    "- Investigating factors that contribute to upsets\n",
    "- Ranking system evaluation\n",
    "- Court surface impact on upsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f686af9c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Export Cleaned Data to Excel\n",
    "\n",
    "Export each year's cleaned data to separate Excel files for easy sharing and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5882fa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016: Exported 2527 matches to c:\\poly_code\\Cleaned_ATP_Data\\cleaned_atp_2016.xlsx\n",
      "2017: Exported 2530 matches to c:\\poly_code\\Cleaned_ATP_Data\\cleaned_atp_2017.xlsx\n",
      "2018: Exported 2555 matches to c:\\poly_code\\Cleaned_ATP_Data\\cleaned_atp_2018.xlsx\n",
      "2019: Exported 2532 matches to c:\\poly_code\\Cleaned_ATP_Data\\cleaned_atp_2019.xlsx\n",
      "2021: Exported 2410 matches to c:\\poly_code\\Cleaned_ATP_Data\\cleaned_atp_2021.xlsx\n",
      "2022: Exported 2547 matches to c:\\poly_code\\Cleaned_ATP_Data\\cleaned_atp_2022.xlsx\n",
      "2023: Exported 2615 matches to c:\\poly_code\\Cleaned_ATP_Data\\cleaned_atp_2023.xlsx\n",
      "2024: Exported 2610 matches to c:\\poly_code\\Cleaned_ATP_Data\\cleaned_atp_2024.xlsx\n",
      "\n",
      "✓ All files exported successfully to: c:\\poly_code\\Cleaned_ATP_Data\n",
      "✓ Total files created: 8\n"
     ]
    }
   ],
   "source": [
    "# Create output directory for cleaned data\n",
    "output_folder = r'c:\\poly_code\\Cleaned_ATP_Data'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Export each year's data to a separate Excel file\n",
    "for year, df in cleaned_betting_odds_dfs.items():\n",
    "    output_file = os.path.join(output_folder, f'cleaned_atp_{year}.xlsx')\n",
    "    df.to_excel(output_file, index=False, engine='openpyxl')\n",
    "    print(f\"{year}: Exported {len(df)} matches to {output_file}\")\n",
    "\n",
    "print(f\"\\n✓ All files exported successfully to: {output_folder}\")\n",
    "print(f\"✓ Total files created: {len(cleaned_betting_odds_dfs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d3664e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported files in c:\\poly_code\\Cleaned_ATP_Data:\n",
      "\n",
      "======================================================================\n",
      "1. cleaned_atp_2016.xlsx          (249.6 KB)\n",
      "2. cleaned_atp_2017.xlsx          (250.3 KB)\n",
      "3. cleaned_atp_2018.xlsx          (252.2 KB)\n",
      "4. cleaned_atp_2019.xlsx          (250.0 KB)\n",
      "5. cleaned_atp_2021.xlsx          (238.0 KB)\n",
      "6. cleaned_atp_2022.xlsx          (251.7 KB)\n",
      "7. cleaned_atp_2023.xlsx          (258.1 KB)\n",
      "8. cleaned_atp_2024.xlsx          (257.4 KB)\n",
      "======================================================================\n",
      "\n",
      "Total: 8 Excel files\n"
     ]
    }
   ],
   "source": [
    "# Verify exported files\n",
    "import glob as glob_module\n",
    "\n",
    "exported_files = glob_module.glob(os.path.join(output_folder, '*.xlsx'))\n",
    "print(f\"Exported files in {output_folder}:\\n\")\n",
    "print(\"=\" * 70)\n",
    "for i, file in enumerate(sorted(exported_files), 1):\n",
    "    file_name = os.path.basename(file)\n",
    "    file_size = os.path.getsize(file) / 1024  # Size in KB\n",
    "    print(f\"{i}. {file_name:30s} ({file_size:.1f} KB)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTotal: {len(exported_files)} Excel files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
